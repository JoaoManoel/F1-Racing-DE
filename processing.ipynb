{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb65a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 21:37:07 WARN Utils: Your hostname, MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.6 instead (on interface en0)\n",
      "23/05/09 21:37:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 21:37:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/09 21:37:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/05/09 21:37:07 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/05/09 21:37:07 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "            .builder\n",
    "            .master('local[1]')\n",
    "            .appName('F1-Racing-DE')\n",
    "            .getOrCreate())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "771d73e2",
   "metadata": {},
   "source": [
    "### Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8439d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import current_timestamp, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5cce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('circuitId', IntegerType(), False),\n",
    "    StructField('circuitRef', StringType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('location', StringType(), True),\n",
    "    StructField('country', StringType(), True),\n",
    "    StructField('lat', DoubleType(), True),\n",
    "    StructField('lng', DoubleType(), True),\n",
    "    StructField('alt', IntegerType(), True),\n",
    "    StructField('url', StringType(), True),\n",
    "]\n",
    "\n",
    "circuits_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4e80cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_df = (spark\n",
    "                .read\n",
    "                .option('header', True)\n",
    "                .schema(circuits_schema)\n",
    "                .format('csv')\n",
    "                .load('data/circuits.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0510214",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_renamed_df = circuits_df\\\n",
    "    .withColumnRenamed('circuitId', 'circuit_id')\\\n",
    "    .withColumnRenamed('circuitRef', 'circuit_ref')\\\n",
    "    .withColumnRenamed('lat', 'latitude')\\\n",
    "    .withColumnRenamed('lng', 'longitude')\\\n",
    "    .withColumnRenamed('alt', 'altitde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a5195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_ingestion_df = circuits_renamed_df.withColumn('ingestion_date', current_timestamp())\n",
    "circuits_final_df = circuits_ingestion_df.drop(col('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bca656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "circuits_final_df.write.mode('overwrite').parquet('data/processed/circuits')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9838785c",
   "metadata": {},
   "source": [
    "### Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aebc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import (\n",
    "    current_timestamp,\n",
    "    col,\n",
    "    when,\n",
    "    lit,\n",
    "    concat,\n",
    "    to_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e571069",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('raceId', IntegerType(), False),\n",
    "    StructField('year', IntegerType(), True),\n",
    "    StructField('round', IntegerType(), True),\n",
    "    StructField('circuitId', IntegerType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('date', StringType(), True),\n",
    "    StructField('time', StringType(), True),\n",
    "    StructField('url', StringType(), True),\n",
    "    StructField('fp1_date', DateType(), True),\n",
    "    StructField('fp1_time', StringType(), True),\n",
    "    StructField('fp2_date', DateType(), True),\n",
    "    StructField('fp2_time', StringType(), True),\n",
    "    StructField('fp3_date', DateType(), True),\n",
    "    StructField('fp3_time', StringType(), True),\n",
    "    StructField('quali_date', DateType(), True),\n",
    "    StructField('quali_time', StringType(), True),\n",
    "    StructField('sprint_date', DateType(), True),\n",
    "    StructField('sprint_time', StringType(), True)\n",
    "]\n",
    "\n",
    "races_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99821ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df = spark\\\n",
    "    .read\\\n",
    "    .option('header', True)\\\n",
    "    .schema(races_schema)\\\n",
    "    .format('csv')\\\n",
    "    .load('data/races.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ffe251",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in races_df.columns:\n",
    "    races_df = races_df.withColumn(\n",
    "        column,\n",
    "        when(col(column) == '\\\\N', None)\\\n",
    "            .otherwise(col(column))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da1be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "races_renamed_df = races_df\\\n",
    "    .withColumnRenamed('raceId', 'race_id')\\\n",
    "    .withColumnRenamed('year', 'race_year')\\\n",
    "    .withColumnRenamed('circuitId', 'circuit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb1de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_column = concat(col('date'), lit(' '), col('time'))\n",
    "\n",
    "race_final_df = races_renamed_df\\\n",
    "    .withColumn('race_timestamp', to_timestamp(ts_column, 'yyyy-MM-dd HH:mm:ss'))\\\n",
    "    .withColumn('ingestion_date', current_timestamp())\\\n",
    "    .drop('date', 'time', 'url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9fe8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "race_final_df.write.partitionBy('race_year').mode('overwrite').parquet('data/processed/races')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d55fc141",
   "metadata": {},
   "source": [
    "### Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19184bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType\n",
    "from pyspark.sql.functions import current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "638232e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('constructorId', IntegerType(), False),\n",
    "    StructField('constructorRef', StringType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('nationality', StringType(), True),\n",
    "    StructField('url', StringType(), True),\n",
    "]\n",
    "\n",
    "constructors_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659316cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors_df = spark\\\n",
    "    .read\\\n",
    "    .option('header', True)\\\n",
    "    .schema(constructors_schema)\\\n",
    "    .format('csv')\\\n",
    "    .load('data/constructors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0139fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors_final_df = constructors_df\\\n",
    "    .withColumnRenamed('constructorId', 'constructor_id')\\\n",
    "    .withColumnRenamed('constructorref', 'constructo_ref')\\\n",
    "    .withColumn('ingestion_date', current_timestamp())\\\n",
    "    .drop('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a202805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors_final_df.write.mode('overwrite').parquet('data/processed/constructors')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a34ed7c4",
   "metadata": {},
   "source": [
    "### Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f685042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "from pyspark.sql.functions import current_timestamp, concat, col, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07a85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('driverId', IntegerType(), False),\n",
    "    StructField('driverRef', StringType(), True),\n",
    "    StructField('number', IntegerType(), True),\n",
    "    StructField('code', IntegerType(), True),\n",
    "    StructField('forename', StringType(), True),\n",
    "    StructField('surname', StringType(), True),\n",
    "    StructField('dob', StringType(), True),\n",
    "    StructField('nationality', StringType(), True),\n",
    "    StructField('url', StringType(), True),\n",
    "]\n",
    "\n",
    "drivers_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f401a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_df = spark\\\n",
    "    .read\\\n",
    "    .option('header', True)\\\n",
    "    .schema(drivers_schema)\\\n",
    "    .format('csv')\\\n",
    "    .load('data/drivers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34d20bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_renamed_df = drivers_df\\\n",
    "    .withColumnRenamed('driverId', 'driver_id')\\\n",
    "    .withColumnRenamed('driverRef', 'driver_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3e7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_transformed_df = drivers_renamed_df\\\n",
    "    .withColumn('name', concat(col('forename'), lit(' '), col('surname')))\\\n",
    "    .withColumn('ingestion_date', current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83721f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_final_df = drivers_transformed_df\\\n",
    "    .drop('forename', 'surname', 'url')\\\n",
    "    .select('driver_id', 'driver_ref', 'name', 'number', 'code', 'dob', 'nationality', 'ingestion_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beef2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_final_df.write.mode('overwrite').parquet('data/processed/drivers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c984f0e7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ef74126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import col, when, current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eb1feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('resultId', IntegerType(), False),\n",
    "    StructField('raceId', IntegerType(), True),\n",
    "    StructField('driverId', IntegerType(), True),\n",
    "    StructField('constructorId', IntegerType(), True),\n",
    "    StructField('number', IntegerType(), True),\n",
    "    StructField('grid', IntegerType(), True),\n",
    "    StructField('position', IntegerType(), True),\n",
    "    StructField('positionText', IntegerType(), True),\n",
    "    StructField('positionOrder', IntegerType(), True),\n",
    "    StructField('points', IntegerType(), True),\n",
    "    StructField('laps', IntegerType(), True),\n",
    "    StructField('time', StringType(), True),\n",
    "    StructField('milliseconds', IntegerType(), True),\n",
    "    StructField('fastestLap', IntegerType(), True),\n",
    "    StructField('rank', IntegerType(), True),\n",
    "    StructField('fastestLapTime', StringType(), True),\n",
    "    StructField('fastestLapSpeed', FloatType(), True),\n",
    "    StructField('statusId', IntegerType(), True)\n",
    "]\n",
    "\n",
    "results_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62607367",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = spark\\\n",
    "    .read\\\n",
    "    .option('header', True)\\\n",
    "    .schema(results_schema)\\\n",
    "    .format('csv')\\\n",
    "    .load('data/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7f0cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in results_df.columns:\n",
    "    results_df = results_df.withColumn(\n",
    "        column,\n",
    "        when(col(column) == '\\\\N', None)\\\n",
    "            .otherwise(col(column))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4320f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_renamed_df = results_df\\\n",
    "    .withColumnRenamed('resultId', 'result_id')\\\n",
    "    .withColumnRenamed('raceId', 'race_id')\\\n",
    "    .withColumnRenamed('driverId', 'driver_id')\\\n",
    "    .withColumnRenamed('constructorId', 'constructor_id')\\\n",
    "    .withColumnRenamed('positionText', 'position_text')\\\n",
    "    .withColumnRenamed('positionOrder', 'position_order')\\\n",
    "    .withColumnRenamed('fastestLap', 'fastest_lap')\\\n",
    "    .withColumnRenamed('fastestLapTime', 'fastest_lap_time')\\\n",
    "    .withColumnRenamed('fastestLapSpeed', 'fastest_lap_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1846e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final_df = results_renamed_df\\\n",
    "    .withColumn('ingestion_date', current_timestamp())\\\n",
    "    .drop('statusId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34aa1a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_final_df\\\n",
    "    .write\\\n",
    "    .mode('overwrite')\\\n",
    "    .partitionBy('race_id')\\\n",
    "    .parquet('data/processed/results')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57674eca",
   "metadata": {},
   "source": [
    "### Pitstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76c8f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2944b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('raceId', IntegerType(), False),\n",
    "    StructField('driverId', IntegerType(), True),\n",
    "    StructField('stop', IntegerType(), True),\n",
    "    StructField('lap', IntegerType(), True),\n",
    "    StructField('time', StringType(), True),\n",
    "    StructField('duration', FloatType(), True),\n",
    "    StructField('milliseconds', IntegerType(), True)\n",
    "]\n",
    "\n",
    "pitstops_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53f2c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitstops_df = spark\\\n",
    "    .read\\\n",
    "    .option('header', True)\\\n",
    "    .schema(pitstops_schema)\\\n",
    "    .format('csv')\\\n",
    "    .load('data/pit_stops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34b50b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitstops_renamed_df = pitstops_df\\\n",
    "    .withColumnRenamed('raceId', 'race_id')\\\n",
    "    .withColumnRenamed('driverId', 'driver_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "191461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitstops_final_df = pitstops_renamed_df.withColumn('ingestion_date', current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a04e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitstops_final_df.write.mode('overwrite').parquet('data/processed/pitstops')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72398c69",
   "metadata": {},
   "source": [
    "### Laptimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35a04a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e71f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('raceId', IntegerType(), False),\n",
    "    StructField('driverId', IntegerType(), True),\n",
    "    StructField('lap', IntegerType(), True),\n",
    "    StructField('position', IntegerType(), True),\n",
    "    StructField('time', StringType(), True),\n",
    "    StructField('milliseconds', IntegerType(), True)\n",
    "]\n",
    "\n",
    "laptimes_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "741b0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptimes_df = spark\\\n",
    "    .read\\\n",
    "    .option('header', True)\\\n",
    "    .schema(laptimes_schema)\\\n",
    "    .format('csv')\\\n",
    "    .load('data/lap_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95d707eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptimes_renamed_df = laptimes_df\\\n",
    "    .withColumnRenamed('raceId', 'race_id')\\\n",
    "    .withColumnRenamed('driverId', 'driver_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35de19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptimes_final_df = laptimes_renamed_df.withColumn('ingestion_date', current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6dcbed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "laptimes_final_df.write.mode('overwrite').parquet('data/processed/laptimes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d61eab4",
   "metadata": {},
   "source": [
    "### Qualifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef04aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import current_timestamp, col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "859ce711",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('qualifyId', IntegerType(), False),\n",
    "    StructField('raceId', IntegerType(), True),\n",
    "    StructField('driverId', IntegerType(), True),\n",
    "    StructField('constructorId', IntegerType(), True),\n",
    "    StructField('number', IntegerType(), True),\n",
    "    StructField('position', IntegerType(), True),\n",
    "    StructField('q1', StringType(), True),\n",
    "    StructField('q2', StringType(), True),\n",
    "    StructField('q3', StringType(), True),\n",
    "]\n",
    "\n",
    "qualifying_schema = StructType(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33db9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_df = spark\\\n",
    "    .read\\\n",
    "    .option('header', True)\\\n",
    "    .schema(qualifying_schema)\\\n",
    "    .format('csv')\\\n",
    "    .load('data/qualifying.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "624b12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in qualifying_df.columns:\n",
    "    qualifying_df = qualifying_df.withColumn(\n",
    "        column,\n",
    "        when(col(column) == '\\\\N', None).otherwise(col(column))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c30440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_renamed_df = qualifying_df\\\n",
    "    .withColumnRenamed('qualifyingId', 'qualifying_id')\\\n",
    "    .withColumnRenamed('raceId', 'race_id')\\\n",
    "    .withColumnRenamed('driverId', 'driver_id')\\\n",
    "    .withColumnRenamed('constructorId', 'constructor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a66fbbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_final_df = qualifying_renamed_df.withColumn('ingestion_date', current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74f476bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_final_df.write.mode('overwrite').parquet('data/processed/qualifying')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
